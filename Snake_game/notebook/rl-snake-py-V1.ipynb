{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T18:23:58.527527Z","iopub.status.busy":"2023-11-18T18:23:58.526858Z","iopub.status.idle":"2023-11-18T18:24:24.549896Z","shell.execute_reply":"2023-11-18T18:24:24.548965Z","shell.execute_reply.started":"2023-11-18T18:23:58.527495Z"},"trusted":true},"outputs":[],"source":["try :\n","    import stable_baselines3\n","except :\n","    ! pip install stable_baselines3\n","    \n","try :\n","    import shimmy\n","except:\n","    ! pip install shimmy"]},{"cell_type":"markdown","metadata":{},"source":["# Snake game logic"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T18:24:24.552022Z","iopub.status.busy":"2023-11-18T18:24:24.551737Z","iopub.status.idle":"2023-11-18T18:24:24.567078Z","shell.execute_reply":"2023-11-18T18:24:24.566203Z","shell.execute_reply.started":"2023-11-18T18:24:24.551996Z"},"trusted":true},"outputs":[],"source":["import random\n","import numpy as np\n","\n","N = 10\n","\n","class SnakeGame:\n","    def __init__(self, size=N):\n","        self.size = size\n","        self.reset()\n","\n","    def reset(self):\n","        self.snake = [(self.size // 2, self.size // 2)]\n","        self.score = 0\n","        self.food = None\n","        self._place_food()\n","        self.game_over = False\n","\n","    def _place_food(self):\n","        while self.food is None or self.food in self.snake:\n","            self.food = (random.randint(0, self.size - 1), random.randint(0, self.size - 1))\n","\n","    def step(self, action):\n","        if self.game_over:\n","            return self.obs, self.score, self.game_over, {}\n","\n","        # Directions: 0-Up, 1-Down, 2-Right,  3-Left\n","        direction = [(0, -1), (0, 1), (1, 0),  (-1, 0)][action]\n","        new_head = (self.snake[0][0] + direction[0], self.snake[0][1] + direction[1])\n","\n","        # Check for game over conditions\n","        if (new_head in self.snake) or new_head[0] < 0 or new_head[0] >= self.size or new_head[1] < 0 or new_head[1] >= self.size:\n","            self.game_over = True\n","            return self.obs, self.score, self.game_over, {}\n","\n","        self.snake.insert(0, new_head)\n","\n","        # Check if snake eats food\n","        if new_head == self.food:\n","            self.score += 1\n","            self._place_food()\n","        else:\n","            self.snake.pop()\n","\n","        self.obs = self.get_observation()\n","        return self.obs, self.score, self.game_over, {}\n","\n","    def get_observation(self):\n","        obs = np.zeros((self.size, self.size))\n","        for x, y in self.snake:\n","            obs[y,x] = 1\n","        x, y = self.food\n","        obs[y,x] = 2\n","        return obs\n","    \n","    def render(self):\n","        obs = self.get_observation()\n","        for line in obs :\n","            print(line, end=\"\\n\")\n","        print()\n","        \n","    def quit(self):\n","        pass"]},{"cell_type":"markdown","metadata":{},"source":["# Gym env "]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"3cce7e58-724b-456d-986d-69cbb5c0c5fe","_uuid":"b36b2165-4c05-4550-b359-e746a5545e1b","collapsed":false,"execution":{"iopub.execute_input":"2023-11-18T18:24:24.568763Z","iopub.status.busy":"2023-11-18T18:24:24.568424Z","iopub.status.idle":"2023-11-18T18:24:24.888057Z","shell.execute_reply":"2023-11-18T18:24:24.887149Z","shell.execute_reply.started":"2023-11-18T18:24:24.568732Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import gym\n","from gym import spaces\n","import numpy as np\n","\n","class SnakeEnv(gym.Env):\n","    \"\"\"\n","    step(action): This method takes an action as input, updates the game state based on that action, returns the new state, the reward gained (or lost), whether the game is over (done), and additional info if necessary.\n","    reset(): This method resets the environment to an initial state and returns this initial state. It's used at the beginning of a new episode.\n","    render(): This method is for visualizing the state of the environment. Depending on how you want to view the game, this could simply update the game window.\n","    close(): This method performs any necessary cleanup, like closing the game window.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(SnakeEnv, self).__init__()\n","        self.action_space = spaces.Discrete(4) # Output\n","        self.observation_space = spaces.Box(low=0, high=2,\n","                                            shape=(1, N, N), dtype=np.int32)\n","        self.snake_game = None\n","        self.previous_score = 0\n","        self.last_distance = np.inf\n","        # StableBaselines throws error if these are not defined\n","        self.spec = None\n","        self.metadata = None\n","        \n","    def seed(self, seed=42): # needed with make_vec_env\n","        np.random.seed(seed)\n","        \n","    def euclidean_distance_centroid(self, obs):\n","        snake_positions = np.argwhere(obs == 1)\n","        food_positions = np.argwhere(obs == 2)\n","        snake_centroid = np.mean(snake_positions, axis=0)\n","        food_position = food_positions[0]  \n","\n","        new_distance = np.linalg.norm(snake_centroid - food_position)\n","        return new_distance\n","    \n","\n","    def feature_gen_euclidean_distance_to_food(self, raw_obs):\n","        n = raw_obs.shape[0]\n","        snake_positions = np.argwhere(raw_obs == 2)\n","        point_coords = snake_positions[0].astype(float)\n","        \n","        x_coords, y_coords = np.meshgrid(np.arange(raw_obs.shape[0]), np.arange(raw_obs.shape[1]))\n","        obs = np.sqrt((x_coords - point_coords[0])**2 + (y_coords - point_coords[1])**2)\n","        return obs.reshape((1, N, N))\n","\n","\n","    def step(self, action):\n","        raw_obs, score, done, _ = self.snake_game.step(action)\n","\n","        # Calculate the Euclidean distance between the snake and the food\n","        new_distance = self.euclidean_distance_centroid(raw_obs)\n","\n","        # Check if the snake has eaten food and update the reward\n","        if self.previous_score != score:\n","            reward = 100\n","            self.previous_score = score\n","        elif done:\n","            reward = -10\n","        else:\n","            reward =  1/10 if new_distance < self.last_distance else -1/100\n","        self.last_distance = new_distance\n","        \n","        obs = self.feature_gen_euclidean_distance_to_food(raw_obs)\n","        return obs, reward, done, _\n","\n","\n","    def reset(self):\n","        self.snake_game = SnakeGame()\n","        return self.snake_game.get_observation()\n","\n","    def render(self, mode='human'):\n","        if mode == 'human':\n","            self.snake_game.render()\n","            \n","    def close(self):\n","        self.snake_game.quit()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Reinforcement learning"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T18:24:24.890711Z","iopub.status.busy":"2023-11-18T18:24:24.890421Z","iopub.status.idle":"2023-11-18T18:24:39.231026Z","shell.execute_reply":"2023-11-18T18:24:39.230141Z","shell.execute_reply.started":"2023-11-18T18:24:24.890686Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["\n","import torch\n","import torch.nn as nn\n","from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n","\n","\n","# The make_vec_env function from Stable Baselines 3 is used to create vectorized environments. \n","# Vectorized environments allow you to run multiple instances of an environment in parallel, \n","# providing a more efficient way to collect experiences (states, actions, rewards, etc.) during training.\n","\n","\n","class CustomCNN(BaseFeaturesExtractor):\n","    \n","    def __init__(self, observation_space, features_dim: int=128):\n","        super(CustomCNN, self).__init__(observation_space, features_dim)\n","        n_input_channels = observation_space.shape[0]\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(n_input_channels, 16, kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 32, kernel_size=2, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","        )\n","        \n","        # Compute shape by doing one forward pass\n","        with torch.no_grad():\n","            n_flatten = self.cnn(\n","                torch.as_tensor(observation_space.sample()[None]).float()\n","            ).shape[1]\n","        \n","        # n_flatten = (N-Conv2d*kernel_size)**2\n","        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n","\n","    # Default policy of PPO (stable_baseline3?)=> take the `action_space` of SnakeEnv for final layer and a softmax activation\n","    def forward(self, observations):\n","        return self.linear(self.cnn(observations))\n","\n","    \n","def evaluate_model(model, eval_env, num_episodes=10):\n","    all_rewards = []\n","    for episode in range(num_episodes):\n","        print(f\"evaluation {episode=}\")\n","        obs = eval_env.reset()\n","        done = False\n","        total_rewards = 0\n","        for _ in range(1000):\n","            action, _states = model.predict(np.reshape(obs, (1, N, N)), deterministic=True)\n","            obs, reward, done, _ = eval_env.step(action)\n","            total_rewards += reward\n","            if done :\n","                break\n","            \n","        all_rewards.append(total_rewards)\n","    average_reward = sum(all_rewards) / num_episodes\n","    return average_reward\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T18:32:13.299790Z","iopub.status.busy":"2023-11-18T18:32:13.298877Z","iopub.status.idle":"2023-11-18T18:32:13.307349Z","shell.execute_reply":"2023-11-18T18:32:13.306332Z","shell.execute_reply.started":"2023-11-18T18:32:13.299759Z"},"trusted":true},"outputs":[],"source":["class LinearQNet(BaseFeaturesExtractor):\n","\n","    def __init__(self, observation_space, features_dim=32):\n","        super(LinearQNet, self).__init__(observation_space, features_dim)\n","        self.flatten = nn.Flatten()\n","        \n","        with torch.no_grad():\n","            n_flatten = self.flatten(\n","                torch.as_tensor(observation_space.sample()[None]).float()\n","            ).shape[1]\n","        \n","        self.linear1 = nn.Linear(n_flatten, features_dim)\n","        self.relu1 = nn.ReLU()\n","        self.linear2 = nn.Linear(features_dim, features_dim)\n","        self.relu2 = nn.ReLU()\n","\n","    def forward(self, X):\n","        out = self.flatten(X)\n","        out = self.linear1(out)\n","        out = self.relu1(out)\n","        out = self.linear2(out)\n","        out = self.relu2(out)\n","\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T18:32:15.334441Z","iopub.status.busy":"2023-11-18T18:32:15.333764Z","iopub.status.idle":"2023-11-18T18:38:04.678077Z","shell.execute_reply":"2023-11-18T18:38:04.677163Z","shell.execute_reply.started":"2023-11-18T18:32:15.334408Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 28.3     |\n","|    ep_rew_mean     | 34.2     |\n","| time/              |          |\n","|    fps             | 749      |\n","|    iterations      | 1        |\n","|    time_elapsed    | 5        |\n","|    total_timesteps | 4096     |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 25.3        |\n","|    ep_rew_mean          | 28.1        |\n","| time/                   |             |\n","|    fps                  | 683         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 11          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.012599082 |\n","|    clip_fraction        | 0.103       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.38       |\n","|    explained_variance   | -0.000483   |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 402         |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0097     |\n","|    value_loss           | 433         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 20.9        |\n","|    ep_rew_mean          | 32.9        |\n","| time/                   |             |\n","|    fps                  | 661         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 18          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.008374862 |\n","|    clip_fraction        | 0.0711      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.36       |\n","|    explained_variance   | 0.034       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 266         |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.00682    |\n","|    value_loss           | 632         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 21.7         |\n","|    ep_rew_mean          | 57           |\n","| time/                   |              |\n","|    fps                  | 654          |\n","|    iterations           | 4            |\n","|    time_elapsed         | 25           |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.0074676913 |\n","|    clip_fraction        | 0.0473       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.34        |\n","|    explained_variance   | 0.0329       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 776          |\n","|    n_updates            | 30           |\n","|    policy_gradient_loss | -0.00495     |\n","|    value_loss           | 728          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 20.9        |\n","|    ep_rew_mean          | 54.9        |\n","| time/                   |             |\n","|    fps                  | 649         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 31          |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.008605085 |\n","|    clip_fraction        | 0.0301      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.33       |\n","|    explained_variance   | 0.0314      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 341         |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.00412    |\n","|    value_loss           | 895         |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 17.4         |\n","|    ep_rew_mean          | 41.8         |\n","| time/                   |              |\n","|    fps                  | 644          |\n","|    iterations           | 6            |\n","|    time_elapsed         | 38           |\n","|    total_timesteps      | 24576        |\n","| train/                  |              |\n","|    approx_kl            | 0.0048947544 |\n","|    clip_fraction        | 0.0256       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.33        |\n","|    explained_variance   | 0.0588       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 542          |\n","|    n_updates            | 50           |\n","|    policy_gradient_loss | -0.00231     |\n","|    value_loss           | 823          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 19.4        |\n","|    ep_rew_mean          | 63.9        |\n","| time/                   |             |\n","|    fps                  | 641         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 44          |\n","|    total_timesteps      | 28672       |\n","| train/                  |             |\n","|    approx_kl            | 0.004865681 |\n","|    clip_fraction        | 0.00923     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.32       |\n","|    explained_variance   | 0.0286      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 322         |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.00268    |\n","|    value_loss           | 765         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 15.2        |\n","|    ep_rew_mean          | 51.7        |\n","| time/                   |             |\n","|    fps                  | 639         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 51          |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.004698676 |\n","|    clip_fraction        | 0.015       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.3        |\n","|    explained_variance   | 0.0474      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 605         |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.00257    |\n","|    value_loss           | 1.1e+03     |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 15.8         |\n","|    ep_rew_mean          | 51.8         |\n","| time/                   |              |\n","|    fps                  | 639          |\n","|    iterations           | 9            |\n","|    time_elapsed         | 57           |\n","|    total_timesteps      | 36864        |\n","| train/                  |              |\n","|    approx_kl            | 0.0072207567 |\n","|    clip_fraction        | 0.0216       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.28        |\n","|    explained_variance   | 0.0333       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 597          |\n","|    n_updates            | 80           |\n","|    policy_gradient_loss | -0.00305     |\n","|    value_loss           | 1.17e+03     |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 16.5         |\n","|    ep_rew_mean          | 50.8         |\n","| time/                   |              |\n","|    fps                  | 638          |\n","|    iterations           | 10           |\n","|    time_elapsed         | 64           |\n","|    total_timesteps      | 40960        |\n","| train/                  |              |\n","|    approx_kl            | 0.0067436714 |\n","|    clip_fraction        | 0.0332       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.28        |\n","|    explained_variance   | 0.00931      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 366          |\n","|    n_updates            | 90           |\n","|    policy_gradient_loss | -0.00432     |\n","|    value_loss           | 1.13e+03     |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 16.2        |\n","|    ep_rew_mean          | 43.7        |\n","| time/                   |             |\n","|    fps                  | 637         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 70          |\n","|    total_timesteps      | 45056       |\n","| train/                  |             |\n","|    approx_kl            | 0.006034377 |\n","|    clip_fraction        | 0.0375      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.29       |\n","|    explained_variance   | 0.00215     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 619         |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.00389    |\n","|    value_loss           | 1.08e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 15.3        |\n","|    ep_rew_mean          | 58.7        |\n","| time/                   |             |\n","|    fps                  | 634         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 77          |\n","|    total_timesteps      | 49152       |\n","| train/                  |             |\n","|    approx_kl            | 0.007669236 |\n","|    clip_fraction        | 0.05        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.27       |\n","|    explained_variance   | 0.0521      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 456         |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.00555    |\n","|    value_loss           | 1.03e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 15.2        |\n","|    ep_rew_mean          | 42.7        |\n","| time/                   |             |\n","|    fps                  | 633         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 83          |\n","|    total_timesteps      | 53248       |\n","| train/                  |             |\n","|    approx_kl            | 0.007089854 |\n","|    clip_fraction        | 0.0246      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.27       |\n","|    explained_variance   | 0.0476      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 317         |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00297    |\n","|    value_loss           | 941         |\n","-----------------------------------------\n","evaluation episode=0\n","evaluation episode=1\n","evaluation episode=2\n","evaluation episode=3\n","evaluation episode=4\n","evaluation episode=5\n","evaluation episode=6\n","evaluation episode=7\n","evaluation episode=8\n","evaluation episode=9\n","Evaluation average reward: -9.588\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 15.6     |\n","|    ep_rew_mean     | 61.8     |\n","| time/              |          |\n","|    fps             | 1116     |\n","|    iterations      | 1        |\n","|    time_elapsed    | 3        |\n","|    total_timesteps | 4096     |\n","---------------------------------\n","--------------------------------------\n","| rollout/                |          |\n","|    ep_len_mean          | 15       |\n","|    ep_rew_mean          | 55.7     |\n","| time/                   |          |\n","|    fps                  | 782      |\n","|    iterations           | 2        |\n","|    time_elapsed         | 10       |\n","|    total_timesteps      | 8192     |\n","| train/                  |          |\n","|    approx_kl            | 0.007973 |\n","|    clip_fraction        | 0.041    |\n","|    clip_range           | 0.2      |\n","|    entropy_loss         | -1.24    |\n","|    explained_variance   | 0.0819   |\n","|    learning_rate        | 0.0003   |\n","|    loss                 | 547      |\n","|    n_updates            | 140      |\n","|    policy_gradient_loss | -0.00391 |\n","|    value_loss           | 1.1e+03  |\n","--------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 12.3       |\n","|    ep_rew_mean          | 57.6       |\n","| time/                   |            |\n","|    fps                  | 718        |\n","|    iterations           | 3          |\n","|    time_elapsed         | 17         |\n","|    total_timesteps      | 12288      |\n","| train/                  |            |\n","|    approx_kl            | 0.00748736 |\n","|    clip_fraction        | 0.0584     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -1.23      |\n","|    explained_variance   | 0.0803     |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 438        |\n","|    n_updates            | 150        |\n","|    policy_gradient_loss | -0.00485   |\n","|    value_loss           | 1.06e+03   |\n","----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 13.1         |\n","|    ep_rew_mean          | 69.6         |\n","| time/                   |              |\n","|    fps                  | 685          |\n","|    iterations           | 4            |\n","|    time_elapsed         | 23           |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.0070522595 |\n","|    clip_fraction        | 0.0577       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.2         |\n","|    explained_variance   | 0.0764       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 681          |\n","|    n_updates            | 160          |\n","|    policy_gradient_loss | -0.00526     |\n","|    value_loss           | 1.26e+03     |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 13.8         |\n","|    ep_rew_mean          | 53.7         |\n","| time/                   |              |\n","|    fps                  | 661          |\n","|    iterations           | 5            |\n","|    time_elapsed         | 30           |\n","|    total_timesteps      | 20480        |\n","| train/                  |              |\n","|    approx_kl            | 0.0055345134 |\n","|    clip_fraction        | 0.0514       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.18        |\n","|    explained_variance   | 0.0343       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 587          |\n","|    n_updates            | 170          |\n","|    policy_gradient_loss | -0.0038      |\n","|    value_loss           | 1.42e+03     |\n","------------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 12.8       |\n","|    ep_rew_mean          | 62.6       |\n","| time/                   |            |\n","|    fps                  | 650        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 37         |\n","|    total_timesteps      | 24576      |\n","| train/                  |            |\n","|    approx_kl            | 0.00466591 |\n","|    clip_fraction        | 0.0453     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -1.19      |\n","|    explained_variance   | 0.0458     |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 355        |\n","|    n_updates            | 180        |\n","|    policy_gradient_loss | -0.00393   |\n","|    value_loss           | 1.3e+03    |\n","----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 12.8       |\n","|    ep_rew_mean          | 67.6       |\n","| time/                   |            |\n","|    fps                  | 641        |\n","|    iterations           | 7          |\n","|    time_elapsed         | 44         |\n","|    total_timesteps      | 28672      |\n","| train/                  |            |\n","|    approx_kl            | 0.00742739 |\n","|    clip_fraction        | 0.0566     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -1.17      |\n","|    explained_variance   | 0.0628     |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 397        |\n","|    n_updates            | 190        |\n","|    policy_gradient_loss | -0.00405   |\n","|    value_loss           | 1.17e+03   |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 12.4        |\n","|    ep_rew_mean          | 63.6        |\n","| time/                   |             |\n","|    fps                  | 634         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 51          |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.005445435 |\n","|    clip_fraction        | 0.0454      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.15       |\n","|    explained_variance   | -0.00315    |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 683         |\n","|    n_updates            | 200         |\n","|    policy_gradient_loss | -0.00427    |\n","|    value_loss           | 1.24e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11.6        |\n","|    ep_rew_mean          | 72.6        |\n","| time/                   |             |\n","|    fps                  | 628         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 58          |\n","|    total_timesteps      | 36864       |\n","| train/                  |             |\n","|    approx_kl            | 0.008110051 |\n","|    clip_fraction        | 0.0571      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.14       |\n","|    explained_variance   | 0.026       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 525         |\n","|    n_updates            | 210         |\n","|    policy_gradient_loss | -0.00391    |\n","|    value_loss           | 1.18e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 12.1         |\n","|    ep_rew_mean          | 53.6         |\n","| time/                   |              |\n","|    fps                  | 626          |\n","|    iterations           | 10           |\n","|    time_elapsed         | 65           |\n","|    total_timesteps      | 40960        |\n","| train/                  |              |\n","|    approx_kl            | 0.0072754584 |\n","|    clip_fraction        | 0.0616       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.11        |\n","|    explained_variance   | -0.0152      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 629          |\n","|    n_updates            | 220          |\n","|    policy_gradient_loss | -0.00367     |\n","|    value_loss           | 1.3e+03      |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 12          |\n","|    ep_rew_mean          | 64.6        |\n","| time/                   |             |\n","|    fps                  | 622         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 72          |\n","|    total_timesteps      | 45056       |\n","| train/                  |             |\n","|    approx_kl            | 0.005112547 |\n","|    clip_fraction        | 0.029       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.12       |\n","|    explained_variance   | 0.0252      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 559         |\n","|    n_updates            | 230         |\n","|    policy_gradient_loss | -0.00232    |\n","|    value_loss           | 1.41e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 11.8         |\n","|    ep_rew_mean          | 65.6         |\n","| time/                   |              |\n","|    fps                  | 620          |\n","|    iterations           | 12           |\n","|    time_elapsed         | 79           |\n","|    total_timesteps      | 49152        |\n","| train/                  |              |\n","|    approx_kl            | 0.0066003418 |\n","|    clip_fraction        | 0.0424       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.11        |\n","|    explained_variance   | 0.0913       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 722          |\n","|    n_updates            | 240          |\n","|    policy_gradient_loss | -0.00391     |\n","|    value_loss           | 1.3e+03      |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 12.5        |\n","|    ep_rew_mean          | 37.6        |\n","| time/                   |             |\n","|    fps                  | 619         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 85          |\n","|    total_timesteps      | 53248       |\n","| train/                  |             |\n","|    approx_kl            | 0.005843275 |\n","|    clip_fraction        | 0.0465      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.11       |\n","|    explained_variance   | -0.000275   |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 731         |\n","|    n_updates            | 250         |\n","|    policy_gradient_loss | -0.00287    |\n","|    value_loss           | 1.25e+03    |\n","-----------------------------------------\n","evaluation episode=0\n","evaluation episode=1\n","evaluation episode=2\n","evaluation episode=3\n","evaluation episode=4\n","evaluation episode=5\n","evaluation episode=6\n","evaluation episode=7\n","evaluation episode=8\n","evaluation episode=9\n","Evaluation average reward: 20.356\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 12.2     |\n","|    ep_rew_mean     | 53.6     |\n","| time/              |          |\n","|    fps             | 1050     |\n","|    iterations      | 1        |\n","|    time_elapsed    | 3        |\n","|    total_timesteps | 4096     |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11.6        |\n","|    ep_rew_mean          | 61.6        |\n","| time/                   |             |\n","|    fps                  | 770         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 10          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.006498114 |\n","|    clip_fraction        | 0.0439      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.09       |\n","|    explained_variance   | 0.0182      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 646         |\n","|    n_updates            | 270         |\n","|    policy_gradient_loss | -0.00354    |\n","|    value_loss           | 1.3e+03     |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11.7        |\n","|    ep_rew_mean          | 74.6        |\n","| time/                   |             |\n","|    fps                  | 706         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 17          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.007166231 |\n","|    clip_fraction        | 0.0496      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.08       |\n","|    explained_variance   | -0.0127     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 665         |\n","|    n_updates            | 280         |\n","|    policy_gradient_loss | -0.00426    |\n","|    value_loss           | 1.4e+03     |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11.1        |\n","|    ep_rew_mean          | 39.6        |\n","| time/                   |             |\n","|    fps                  | 679         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 24          |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.006892585 |\n","|    clip_fraction        | 0.0527      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.05       |\n","|    explained_variance   | 0.0718      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 456         |\n","|    n_updates            | 290         |\n","|    policy_gradient_loss | -0.00334    |\n","|    value_loss           | 1.49e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 10.9         |\n","|    ep_rew_mean          | 54.6         |\n","| time/                   |              |\n","|    fps                  | 659          |\n","|    iterations           | 5            |\n","|    time_elapsed         | 31           |\n","|    total_timesteps      | 20480        |\n","| train/                  |              |\n","|    approx_kl            | 0.0045565646 |\n","|    clip_fraction        | 0.0368       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.04        |\n","|    explained_variance   | 0.048        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 586          |\n","|    n_updates            | 300          |\n","|    policy_gradient_loss | -0.00207     |\n","|    value_loss           | 1.32e+03     |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11          |\n","|    ep_rew_mean          | 65.6        |\n","| time/                   |             |\n","|    fps                  | 649         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 37          |\n","|    total_timesteps      | 24576       |\n","| train/                  |             |\n","|    approx_kl            | 0.007485235 |\n","|    clip_fraction        | 0.0766      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.02       |\n","|    explained_variance   | 0.032       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 905         |\n","|    n_updates            | 310         |\n","|    policy_gradient_loss | -0.00314    |\n","|    value_loss           | 1.45e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 11          |\n","|    ep_rew_mean          | 77.6        |\n","| time/                   |             |\n","|    fps                  | 645         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 44          |\n","|    total_timesteps      | 28672       |\n","| train/                  |             |\n","|    approx_kl            | 0.004802628 |\n","|    clip_fraction        | 0.0385      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.02       |\n","|    explained_variance   | 0.0622      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 643         |\n","|    n_updates            | 320         |\n","|    policy_gradient_loss | -0.0023     |\n","|    value_loss           | 1.48e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 10.6        |\n","|    ep_rew_mean          | 52.6        |\n","| time/                   |             |\n","|    fps                  | 640         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 51          |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.006389919 |\n","|    clip_fraction        | 0.0595      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.01       |\n","|    explained_variance   | 0.0321      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 635         |\n","|    n_updates            | 330         |\n","|    policy_gradient_loss | -0.00281    |\n","|    value_loss           | 1.49e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 10.6         |\n","|    ep_rew_mean          | 66.6         |\n","| time/                   |              |\n","|    fps                  | 636          |\n","|    iterations           | 9            |\n","|    time_elapsed         | 57           |\n","|    total_timesteps      | 36864        |\n","| train/                  |              |\n","|    approx_kl            | 0.0052328818 |\n","|    clip_fraction        | 0.0397       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.968       |\n","|    explained_variance   | 0.0584       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 749          |\n","|    n_updates            | 340          |\n","|    policy_gradient_loss | -0.00332     |\n","|    value_loss           | 1.53e+03     |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 10.5        |\n","|    ep_rew_mean          | 66.6        |\n","| time/                   |             |\n","|    fps                  | 635         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 64          |\n","|    total_timesteps      | 40960       |\n","| train/                  |             |\n","|    approx_kl            | 0.004868638 |\n","|    clip_fraction        | 0.0424      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.96       |\n","|    explained_variance   | 0.0471      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 537         |\n","|    n_updates            | 350         |\n","|    policy_gradient_loss | -0.00225    |\n","|    value_loss           | 1.48e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 10.1        |\n","|    ep_rew_mean          | 65.5        |\n","| time/                   |             |\n","|    fps                  | 633         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 71          |\n","|    total_timesteps      | 45056       |\n","| train/                  |             |\n","|    approx_kl            | 0.006957626 |\n","|    clip_fraction        | 0.0646      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.957      |\n","|    explained_variance   | 0.0288      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 687         |\n","|    n_updates            | 360         |\n","|    policy_gradient_loss | -0.00441    |\n","|    value_loss           | 1.58e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 10.3         |\n","|    ep_rew_mean          | 44.6         |\n","| time/                   |              |\n","|    fps                  | 632          |\n","|    iterations           | 12           |\n","|    time_elapsed         | 77           |\n","|    total_timesteps      | 49152        |\n","| train/                  |              |\n","|    approx_kl            | 0.0057085827 |\n","|    clip_fraction        | 0.0383       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.942       |\n","|    explained_variance   | 0.0749       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 799          |\n","|    n_updates            | 370          |\n","|    policy_gradient_loss | -0.00214     |\n","|    value_loss           | 1.6e+03      |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 9.24         |\n","|    ep_rew_mean          | 66.5         |\n","| time/                   |              |\n","|    fps                  | 632          |\n","|    iterations           | 13           |\n","|    time_elapsed         | 84           |\n","|    total_timesteps      | 53248        |\n","| train/                  |              |\n","|    approx_kl            | 0.0071439557 |\n","|    clip_fraction        | 0.0675       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.924       |\n","|    explained_variance   | 0.0681       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 1.33e+03     |\n","|    n_updates            | 380          |\n","|    policy_gradient_loss | -0.00324     |\n","|    value_loss           | 1.59e+03     |\n","------------------------------------------\n","evaluation episode=0\n","evaluation episode=1\n","evaluation episode=2\n","evaluation episode=3\n","evaluation episode=4\n","evaluation episode=5\n","evaluation episode=6\n","evaluation episode=7\n","evaluation episode=8\n","evaluation episode=9\n","Evaluation average reward: 10.335999999999999\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 10.1     |\n","|    ep_rew_mean     | 67.5     |\n","| time/              |          |\n","|    fps             | 1113     |\n","|    iterations      | 1        |\n","|    time_elapsed    | 3        |\n","|    total_timesteps | 4096     |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 10.7        |\n","|    ep_rew_mean          | 46.5        |\n","| time/                   |             |\n","|    fps                  | 801         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 10          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.005912992 |\n","|    clip_fraction        | 0.0465      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.927      |\n","|    explained_variance   | 0.0671      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 790         |\n","|    n_updates            | 400         |\n","|    policy_gradient_loss | -0.00308    |\n","|    value_loss           | 1.38e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 10.1        |\n","|    ep_rew_mean          | 76.5        |\n","| time/                   |             |\n","|    fps                  | 734         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 16          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.007749355 |\n","|    clip_fraction        | 0.0698      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.929      |\n","|    explained_variance   | 0.0673      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 665         |\n","|    n_updates            | 410         |\n","|    policy_gradient_loss | -0.00445    |\n","|    value_loss           | 1.72e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 10.3         |\n","|    ep_rew_mean          | 49.6         |\n","| time/                   |              |\n","|    fps                  | 701          |\n","|    iterations           | 4            |\n","|    time_elapsed         | 23           |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.0066361306 |\n","|    clip_fraction        | 0.0508       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.91        |\n","|    explained_variance   | 0.0997       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 555          |\n","|    n_updates            | 420          |\n","|    policy_gradient_loss | -0.00382     |\n","|    value_loss           | 1.78e+03     |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 9.99         |\n","|    ep_rew_mean          | 69.5         |\n","| time/                   |              |\n","|    fps                  | 679          |\n","|    iterations           | 5            |\n","|    time_elapsed         | 30           |\n","|    total_timesteps      | 20480        |\n","| train/                  |              |\n","|    approx_kl            | 0.0067491005 |\n","|    clip_fraction        | 0.0559       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.897       |\n","|    explained_variance   | 0.0414       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 747          |\n","|    n_updates            | 430          |\n","|    policy_gradient_loss | -0.00371     |\n","|    value_loss           | 1.59e+03     |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 9.93         |\n","|    ep_rew_mean          | 72.5         |\n","| time/                   |              |\n","|    fps                  | 670          |\n","|    iterations           | 6            |\n","|    time_elapsed         | 36           |\n","|    total_timesteps      | 24576        |\n","| train/                  |              |\n","|    approx_kl            | 0.0084201675 |\n","|    clip_fraction        | 0.057        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.875       |\n","|    explained_variance   | 0.0674       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 1.18e+03     |\n","|    n_updates            | 440          |\n","|    policy_gradient_loss | -0.0039      |\n","|    value_loss           | 1.51e+03     |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 10.2        |\n","|    ep_rew_mean          | 64.5        |\n","| time/                   |             |\n","|    fps                  | 662         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 43          |\n","|    total_timesteps      | 28672       |\n","| train/                  |             |\n","|    approx_kl            | 0.008409284 |\n","|    clip_fraction        | 0.0844      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.858      |\n","|    explained_variance   | 0.0474      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 644         |\n","|    n_updates            | 450         |\n","|    policy_gradient_loss | -0.00622    |\n","|    value_loss           | 1.55e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 10.5         |\n","|    ep_rew_mean          | 62.6         |\n","| time/                   |              |\n","|    fps                  | 657          |\n","|    iterations           | 8            |\n","|    time_elapsed         | 49           |\n","|    total_timesteps      | 32768        |\n","| train/                  |              |\n","|    approx_kl            | 0.0053893523 |\n","|    clip_fraction        | 0.0486       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.852       |\n","|    explained_variance   | 0.0821       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 541          |\n","|    n_updates            | 460          |\n","|    policy_gradient_loss | -0.00329     |\n","|    value_loss           | 1.57e+03     |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 9.72        |\n","|    ep_rew_mean          | 44.6        |\n","| time/                   |             |\n","|    fps                  | 650         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 56          |\n","|    total_timesteps      | 36864       |\n","| train/                  |             |\n","|    approx_kl            | 0.005816425 |\n","|    clip_fraction        | 0.0377      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.838      |\n","|    explained_variance   | 0.0962      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 698         |\n","|    n_updates            | 470         |\n","|    policy_gradient_loss | -0.00335    |\n","|    value_loss           | 1.68e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 9.46         |\n","|    ep_rew_mean          | 67.5         |\n","| time/                   |              |\n","|    fps                  | 645          |\n","|    iterations           | 10           |\n","|    time_elapsed         | 63           |\n","|    total_timesteps      | 40960        |\n","| train/                  |              |\n","|    approx_kl            | 0.0075909807 |\n","|    clip_fraction        | 0.0706       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.848       |\n","|    explained_variance   | 0.0687       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 913          |\n","|    n_updates            | 480          |\n","|    policy_gradient_loss | -0.00327     |\n","|    value_loss           | 1.57e+03     |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 9.84        |\n","|    ep_rew_mean          | 73.5        |\n","| time/                   |             |\n","|    fps                  | 643         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 70          |\n","|    total_timesteps      | 45056       |\n","| train/                  |             |\n","|    approx_kl            | 0.009778207 |\n","|    clip_fraction        | 0.1         |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.837      |\n","|    explained_variance   | 0.0872      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 832         |\n","|    n_updates            | 490         |\n","|    policy_gradient_loss | -0.00483    |\n","|    value_loss           | 1.66e+03    |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 9.45        |\n","|    ep_rew_mean          | 63.5        |\n","| time/                   |             |\n","|    fps                  | 640         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 76          |\n","|    total_timesteps      | 49152       |\n","| train/                  |             |\n","|    approx_kl            | 0.008905872 |\n","|    clip_fraction        | 0.0707      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.8        |\n","|    explained_variance   | 0.0924      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 726         |\n","|    n_updates            | 500         |\n","|    policy_gradient_loss | -0.00436    |\n","|    value_loss           | 1.92e+03    |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 9.21         |\n","|    ep_rew_mean          | 71.5         |\n","| time/                   |              |\n","|    fps                  | 638          |\n","|    iterations           | 13           |\n","|    time_elapsed         | 83           |\n","|    total_timesteps      | 53248        |\n","| train/                  |              |\n","|    approx_kl            | 0.0075187413 |\n","|    clip_fraction        | 0.05         |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.806       |\n","|    explained_variance   | 0.081        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 964          |\n","|    n_updates            | 510          |\n","|    policy_gradient_loss | -0.00411     |\n","|    value_loss           | 2.01e+03     |\n","------------------------------------------\n","evaluation episode=0\n","evaluation episode=1\n","evaluation episode=2\n","evaluation episode=3\n","evaluation episode=4\n","evaluation episode=5\n","evaluation episode=6\n","evaluation episode=7\n","evaluation episode=8\n","evaluation episode=9\n","Evaluation average reward: 20.278\n","CPU times: user 5min 44s, sys: 1.7 s, total: 5min 45s\n","Wall time: 5min 49s\n"]}],"source":["%%time   \n","from stable_baselines3 import PPO,DQN, A2C\n","from stable_baselines3.common.env_util import make_vec_env\n","from stable_baselines3.common.logger import configure\n","from stable_baselines3.common.utils import get_schedule_fn\n","\n","train_env = make_vec_env(lambda: SnakeEnv(), n_envs=2)\n","eval_env = SnakeEnv()\n","\n","\n","policy_kwargs = dict(\n","    features_extractor_class=LinearQNet,\n",")\n","\n","learning_rate_schedule = get_schedule_fn(0.0003)\n","model = PPO(\"CnnPolicy\", train_env, policy_kwargs=policy_kwargs, verbose=2,learning_rate=learning_rate_schedule)               \n","\n","# new_logger = configure(\"path_to_save_logs\", [\"stdout\", \"tensorboard\"])\n","# model.set_logger(new_logger) # Run TensorBoard in a terminal: tensorboard --logdir=path_to_save_logs\n","\n","\n","total_timesteps = 200_000\n","eval_interval = 50_000  \n","num_eval_episodes = 100  \n","\n","# Training loop with periodic evaluation\n","for _ in range(0, total_timesteps, eval_interval):\n","    model.learn(total_timesteps=eval_interval)\n","    avg_reward = evaluate_model(model, eval_env, num_episodes=10)\n","    print(f\"Evaluation average reward: {avg_reward}\")\n","\n","model.save(\"ppo_snake\")"]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T19:02:30.933461Z","iopub.status.busy":"2023-11-18T19:02:30.932736Z","iopub.status.idle":"2023-11-18T19:02:47.407731Z","shell.execute_reply":"2023-11-18T19:02:47.406735Z","shell.execute_reply.started":"2023-11-18T19:02:30.933423Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 1. 0. 2. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 1. 1. 2. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]},{"name":"stdout","output_type":"stream","text":["press enter to continue \n"]},{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 2. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","\n"]}],"source":["from stable_baselines3 import PPO \n","\n","\n","env = SnakeEnv()\n","# model = PPO.load(\"ppo_snake\", env=env)\n","\n","obs = env.reset()\n","done = False\n","env.render()\n","while not done:\n","    input(\"press enter to continue\")\n","    action, _info = model.predict(np.reshape(obs, (1, N, N)), deterministic=True)\n","    obs, reward, done, _ = env.step(action)\n","    env.render()\n","    #input(\"press key for next step\")\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
